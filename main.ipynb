{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbosity is set to 1 (active). Pass verbose=0 to make quieter.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:33<00:00, 16.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overwrite is on. Deleting existing index colpali to build a new one.\n",
      "Added page 1 of document 0 to index.\n",
      "Added page 2 of document 0 to index.\n",
      "Added page 3 of document 0 to index.\n",
      "Added page 4 of document 0 to index.\n",
      "Added page 5 of document 0 to index.\n",
      "Added page 6 of document 0 to index.\n",
      "Added page 7 of document 0 to index.\n",
      "Added page 8 of document 0 to index.\n",
      "Added page 9 of document 0 to index.\n",
      "Added page 10 of document 0 to index.\n",
      "Added page 11 of document 0 to index.\n",
      "Added page 12 of document 0 to index.\n",
      "Added page 13 of document 0 to index.\n",
      "Added page 14 of document 0 to index.\n",
      "Added page 15 of document 0 to index.\n",
      "Index exported to .byaldi\\colpali\n",
      "Index exported to .byaldi\\colpali\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from byaldi import RAGMultiModalModel\n",
    "\n",
    "model0= RAGMultiModalModel.from_pretrained('vidore/colpali-v1.2')\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "model0.index(input_path=Path('attention_is_all_you_need.pdf'),\n",
    "            index_name='colpali',\n",
    "            store_collection_with_index=True,\n",
    "            overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0.index(input_path=Path('attention_is_all_you_need.pdf'),\n",
    "            index_name='colpali',\n",
    "            store_collection_with_index=True,\n",
    "            overwrite=True)\n",
    "query = \"\"\"extract the results of evaluations from table 2\"\"\"\n",
    "\n",
    "results = model0.search(query,k=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from PIL import Image\n",
    "from io import BytesIO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved as 'decoded_image.png'\n"
     ]
    }
   ],
   "source": [
    "base64_string = results[0]['base64']\n",
    "\n",
    "# Decode Base64 string to binary data\n",
    "image_data = base64.b64decode(base64_string)\n",
    "\n",
    "# Write binary data to an image file\n",
    "with open(\"decoded_image.png\", \"wb\") as image_file:\n",
    "    image_file.write(image_data)\n",
    "\n",
    "print(\"Image saved as 'decoded_image.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model='llama3.2-vision' created_at='2025-01-29T13:36:40.9375092Z' done=True done_reason='stop' total_duration=10858931700 load_duration=79794800 prompt_eval_count=18 prompt_eval_duration=901000000 eval_count=40 eval_duration=9004000000 message=Message(role='assistant', content='This appears to be a page from an academic paper about artificial intelligence. The page has tables and text discussing the performance of various machine learning models, with results presented in terms of accuracy and efficiency.', images=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(\n",
    "    model='llama3.2-vision',\n",
    "    messages=[{\n",
    "        'role': 'user',\n",
    "        'content': 'What is in this image?',\n",
    "        'images': ['decoded_image.png']\n",
    "    }]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import camelot\n",
    "# tables = camelot.read_pdf('31122024.pdf', pages='2',flavor='stream')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tabula \n",
    "dfs=tabula.read_pdf(\"attention_is_all_you_need.pdf\",pages='all')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
